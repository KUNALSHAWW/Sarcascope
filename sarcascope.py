# -*- coding: utf-8 -*-
"""Unique.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QUvjIuw_PEoK7GGJhaR8ky1Dy7gL2Nyf
"""

!pip install transformers torch torchvision datasets scikit-learn matplotlib seaborn wordcloud plotly pandas numpy requests beautifulsoup4 textblob vaderSentiment

!pip install -U transformers -q

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import warnings
warnings.filterwarnings('ignore')

import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression

import re
import requests
from bs4 import BeautifulSoup
import json
from datetime import datetime
import time
from collections import Counter
from wordcloud import WordCloud
from textblob import TextBlob
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
# Download and extract the dataset
print("üì• Downloading IMDB dataset...")
!wget -q "https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz"
!tar -xzf aclImdb_v1.tar.gz
print("‚úÖ Dataset downloaded and extracted successfully!")

def load_imdb_data():
    """Load and preprocess IMDB dataset"""
    import os

    def read_files(directory):
        texts = []
        labels = []
        for filename in os.listdir(directory):
            if filename.endswith('.txt'):
                with open(os.path.join(directory, filename), 'r', encoding='utf-8') as f:
                    text = f.read()
                    texts.append(text)
                    # Extract rating from filename (if available)
                    rating = filename.split('_')[-1].split('.')[0]
                    labels.append(1 if 'pos' in directory else 0)
        return texts, labels

    # Load training data
    train_pos_texts, train_pos_labels = read_files('aclImdb/train/pos')
    train_neg_texts, train_neg_labels = read_files('aclImdb/train/neg')

    # Load test data
    test_pos_texts, test_pos_labels = read_files('aclImdb/test/pos')
    test_neg_texts, test_neg_labels = read_files('aclImdb/test/neg')

    # Combine all data
    all_texts = train_pos_texts + train_neg_texts + test_pos_texts + test_neg_texts
    all_labels = train_pos_labels + train_neg_labels + test_pos_labels + test_neg_labels

    return pd.DataFrame({
        'review': all_texts,
        'sentiment': all_labels
    })

def extract_movie_info(review_text):
    """Extract movie information from review text using pattern matching"""
    # Common patterns for movie titles, years, genres
    year_pattern = r'\b(19\d{2}|20\d{2})\b'

    # Extract year
    year_match = re.search(year_pattern, review_text)
    year = int(year_match.group(1)) if year_match else None

    # Estimate genre based on keywords (simplified approach)
    genre_keywords = {
        'action': ['action', 'fight', 'battle', 'explosion', 'chase', 'weapon', 'combat'],
        'comedy': ['funny', 'laugh', 'humor', 'comedy', 'hilarious', 'amusing', 'joke'],
        'drama': ['emotional', 'drama', 'dramatic', 'touching', 'moving', 'deep'],
        'horror': ['scary', 'horror', 'frightening', 'terrifying', 'fear', 'nightmare'],
        'romance': ['love', 'romance', 'romantic', 'relationship', 'couple', 'heart'],
        'thriller': ['suspense', 'thriller', 'mystery', 'tense', 'twist', 'plot'],
        'sci-fi': ['sci-fi', 'science fiction', 'future', 'space', 'alien', 'robot'],
        'fantasy': ['fantasy', 'magic', 'wizard', 'dragon', 'supernatural', 'myth']
    }

    text_lower = review_text.lower()
    genre_scores = {}

    for genre, keywords in genre_keywords.items():
        score = sum(1 for keyword in keywords if keyword in text_lower)
        genre_scores[genre] = score

    # Get the genre with highest score
    predicted_genre = max(genre_scores, key=genre_scores.get) if max(genre_scores.values()) > 0 else 'unknown'

    return year, predicted_genre

# Load the data
print("üìä Loading IMDB dataset...")
df = load_imdb_data()
print(f"Dataset shape: {df.shape}")
print(f"Sentiment distribution:\n{df['sentiment'].value_counts()}")

# Apply movie info extraction
print("üé¨ Extracting movie metadata...")
df[['year', 'genre']] = df['review'].apply(lambda x: pd.Series(extract_movie_info(x)))

# Handle missing years by using median year
median_year = df['year'].median()
df['year'] = df['year'].fillna(median_year)

print(f"Year distribution:\n{df['year'].value_counts().sort_index()}")
print(f"Genre distribution:\n{df['genre'].value_counts()}")
print("‚úÖ Data loading and preprocessing complete!")

class SarcasmDetector:
    def __init__(self):
        self.sarcasm_indicators = [
            # Punctuation patterns
            r'\.{3,}',  # Multiple dots
            r'!{2,}',   # Multiple exclamation marks
            r'\?{2,}',  # Multiple question marks

            # Sarcastic phrases
            r'\b(oh wow|oh great|how wonderful|fantastic|brilliant|amazing|perfect)\b',
            r'\b(sure thing|of course|obviously|clearly|totally|absolutely)\b',
            r'\b(what a surprise|shocking|who would have thought)\b',

            # Contradictory patterns
            r'\b(not bad|not terrible|not awful)\b',
            r'\b(could be worse|at least)\b',

            # Extreme comparisons
            r'\b(worst|terrible|awful|horrible|disgusting) .* (ever|in history|of all time)\b',
            r'\b(best|greatest|most amazing) .* (not|never|hardly)\b'
        ]

        # Load pre-trained sentiment analyzer for contradiction detection
        self.sentiment_analyzer = SentimentIntensityAnalyzer()

        # Initialize BERT-based classifier (using RoBERTa for better sarcasm detection)
        self.tokenizer = AutoTokenizer.from_pretrained('cardiffnlp/twitter-roberta-base-sentiment-latest')
        self.model = AutoModelForSequenceClassification.from_pretrained('cardiffnlp/twitter-roberta-base-sentiment-latest')

    def detect_sarcasm_patterns(self, text):
        """Detect sarcasm using pattern matching"""
        sarcasm_score = 0
        text_lower = text.lower()

        for pattern in self.sarcasm_indicators:
            matches = re.findall(pattern, text_lower)
            sarcasm_score += len(matches)

        return sarcasm_score

    def detect_sentiment_contradiction(self, text):
        """Detect sarcasm through sentiment contradiction"""
        # Split text into sentences
        sentences = re.split(r'[.!?]+', text)

        if len(sentences) < 2:
            return 0

        sentiments = []
        for sentence in sentences:
            if sentence.strip():
                sentiment = self.sentiment_analyzer.polarity_scores(sentence.strip())
                sentiments.append(sentiment['compound'])

        # Check for contradictory sentiments
        if len(sentiments) >= 2:
            # Calculate variance in sentiment scores
            variance = np.var(sentiments)
            return variance

        return 0

    def detect_bert_sarcasm(self, text):
        """Use BERT to detect potential sarcasm through sentiment intensity"""
        # Tokenize and get predictions
        inputs = self.tokenizer(text, return_tensors='pt', truncation=True, max_length=512)

        with torch.no_grad():
            outputs = self.model(**inputs)
            probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)

        # Get sentiment scores
        neg_score = probabilities[0][0].item()
        neu_score = probabilities[0][1].item()
        pos_score = probabilities[0][2].item()

        # Sarcasm often shows extreme sentiment with neutral undertones
        # or high positive/negative with unexpected context
        sarcasm_likelihood = abs(pos_score - neg_score) * neu_score

        return sarcasm_likelihood

    def predict_sarcasm(self, text):
        """Combine all methods to predict sarcasm"""
        pattern_score = self.detect_sarcasm_patterns(text)
        contradiction_score = self.detect_sentiment_contradiction(text)
        bert_score = self.detect_bert_sarcasm(text)

        # Normalize scores
        pattern_score = min(pattern_score / 3, 1.0)  # Normalize to 0-1
        contradiction_score = min(contradiction_score * 2, 1.0)  # Normalize to 0-1
        bert_score = min(bert_score * 3, 1.0)  # Normalize to 0-1

        # Weighted combination
        final_score = (0.4 * pattern_score + 0.3 * contradiction_score + 0.3 * bert_score)

        return final_score > 0.3  # Threshold for sarcasm detection

# Initialize sarcasm detector
print("ü§ñ Initializing sarcasm detector...")
sarcasm_detector = SarcasmDetector()

# Apply sarcasm detection (on a sample for speed)
sample_size = 5000  # Reduce for faster processing
df_sample = df.sample(n=sample_size, random_state=42)

print("üîç Detecting sarcasm in reviews...")
df_sample['is_sarcastic'] = df_sample['review'].apply(sarcasm_detector.predict_sarcasm)

print(f"Sarcasm detection results:\n{df_sample['is_sarcastic'].value_counts()}")
print("‚úÖ Sarcasm detection complete!")

class SarcasmAwareSentimentAnalyzer:
    def __init__(self):
        self.base_analyzer = SentimentIntensityAnalyzer()
        self.sentiment_pipeline = pipeline('sentiment-analysis',
                                         model='cardiffnlp/twitter-roberta-base-sentiment-latest')

    def analyze_sentiment(self, text, is_sarcastic=False):
        """Analyze sentiment with sarcasm awareness"""
        # Get base sentiment
        base_sentiment = self.base_analyzer.polarity_scores(text)

        # Get BERT-based sentiment
        bert_result = self.sentiment_pipeline(text[:512])[0]  # Truncate for BERT
        bert_score = bert_result['score'] if bert_result['label'] == 'POSITIVE' else -bert_result['score']

        # Adjust for sarcasm
        if is_sarcastic:
            # Flip the sentiment for sarcastic reviews
            adjusted_compound = -base_sentiment['compound']
            adjusted_bert = -bert_score
        else:
            adjusted_compound = base_sentiment['compound']
            adjusted_bert = bert_score

        # Combine scores
        final_score = (adjusted_compound + adjusted_bert) / 2

        return {
            'compound': final_score,
            'positive': base_sentiment['pos'] if not is_sarcastic else base_sentiment['neg'],
            'negative': base_sentiment['neg'] if not is_sarcastic else base_sentiment['pos'],
            'neutral': base_sentiment['neu'],
            'confidence': abs(final_score)
        }

# Initialize sentiment analyzer
sentiment_analyzer = SarcasmAwareSentimentAnalyzer()

# Apply sentiment analysis
print("üí≠ Analyzing sentiment with sarcasm awareness...")
sentiment_results = []

for idx, row in df_sample.iterrows():
    result = sentiment_analyzer.analyze_sentiment(row['review'], row['is_sarcastic'])
    sentiment_results.append(result)

# Add sentiment results to dataframe
for key in ['compound', 'positive', 'negative', 'neutral', 'confidence']:
    df_sample[f'sentiment_{key}'] = [result[key] for result in sentiment_results]

print("‚úÖ Sentiment analysis complete!")

def create_timeline_analysis(df):
    """Create timeline analysis of sentiment evolution"""
    # Group by year and calculate average sentiment
    yearly_sentiment = df.groupby('year').agg({
        'sentiment_compound': 'mean',
        'sentiment_confidence': 'mean',
        'is_sarcastic': 'mean',
        'review': 'count'
    }).reset_index()

    yearly_sentiment.columns = ['year', 'avg_sentiment', 'avg_confidence', 'sarcasm_rate', 'review_count']

    # Calculate moving averages
    yearly_sentiment['sentiment_ma3'] = yearly_sentiment['avg_sentiment'].rolling(window=3, center=True).mean()
    yearly_sentiment['sarcasm_ma3'] = yearly_sentiment['sarcasm_rate'].rolling(window=3, center=True).mean()

    return yearly_sentiment

def create_genre_analysis(df):
    """Create genre-aware sentiment analysis"""
    genre_analysis = df.groupby('genre').agg({
        'sentiment_compound': ['mean', 'std', 'count'],
        'sentiment_confidence': 'mean',
        'is_sarcastic': 'mean'
    }).reset_index()

    # Flatten column names
    genre_analysis.columns = ['genre', 'avg_sentiment', 'sentiment_std', 'review_count', 'avg_confidence', 'sarcasm_rate']

    # Calculate genre sentiment ranges
    genre_analysis['sentiment_range'] = genre_analysis['sentiment_std'] * 2

    return genre_analysis

# Create timeline analysis
print("üìà Creating timeline analysis...")
timeline_data = create_timeline_analysis(df_sample)

# Create genre analysis
print("üé≠ Creating genre analysis...")
genre_data = create_genre_analysis(df_sample)

print("‚úÖ Timeline and genre analysis complete!")

def create_genre_analysis(df):
    """Create genre-aware sentiment analysis"""
    genre_analysis = df.groupby('genre').agg({
        'sentiment_compound': ['mean', 'std', 'count'],
        'sentiment_confidence': 'mean',
        'is_sarcastic': 'mean'
    }).reset_index()

    # Flatten column names
    genre_analysis.columns = ['genre', 'avg_sentiment', 'sentiment_std', 'review_count', 'avg_confidence', 'sarcasm_rate']

    # Calculate genre sentiment ranges
    genre_analysis['sentiment_range'] = genre_analysis['sentiment_std'] * 2

    return genre_analysis

# Create genre analysis
genre_data = create_genre_analysis(df_sample)

# VISUALIZATION AND RESULTS
print("Creating visualizations...")

# Set up the plotting style
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

# Create comprehensive dashboard
fig = plt.figure(figsize=(20, 15))

# 1. Sarcasm Detection Overview
ax1 = plt.subplot(2, 4, 1)
sarcasm_counts = df_sample['is_sarcastic'].value_counts()
plt.pie(sarcasm_counts.values, labels=['Non-Sarcastic', 'Sarcastic'], autopct='%1.1f%%', startangle=90)
plt.title('Sarcasm Detection Results')

# 2. Sentiment Distribution by Sarcasm
ax2 = plt.subplot(2, 4, 2)
sns.boxplot(data=df_sample, x='is_sarcastic', y='sentiment_compound')
plt.title('Sentiment Distribution by Sarcasm')
plt.xlabel('Is Sarcastic')
plt.ylabel('Sentiment Score')

# 3. Timeline Analysis
ax3 = plt.subplot(2, 4, 3)
plt.plot(timeline_data['year'], timeline_data['avg_sentiment'], 'b-', label='Average Sentiment', linewidth=2)
plt.plot(timeline_data['year'], timeline_data['sentiment_ma3'], 'r--', label='3-Year Moving Average', linewidth=2)
plt.title('Sentiment Timeline Evolution')
plt.xlabel('Year')
plt.ylabel('Average Sentiment')
plt.legend()
plt.grid(True, alpha=0.3)

# 4. Sarcasm Rate Over Time
ax4 = plt.subplot(2, 4, 4)
plt.plot(timeline_data['year'], timeline_data['sarcasm_rate'], 'g-', linewidth=2)
plt.title('Sarcasm Rate Over Time')
plt.xlabel('Year')
plt.ylabel('Sarcasm Rate')
plt.grid(True, alpha=0.3)

# 5. Genre-wise Sentiment Analysis
ax5 = plt.subplot(2, 4, 5)
genre_data_sorted = genre_data.sort_values('avg_sentiment', ascending=True)
bars = plt.barh(genre_data_sorted['genre'], genre_data_sorted['avg_sentiment'])
plt.title('Average Sentiment by Genre')
plt.xlabel('Average Sentiment Score')
plt.colorbar(plt.cm.ScalarMappable(cmap='RdYlBu'), ax=ax5)

# 6. Sarcasm Rate by Genre
ax6 = plt.subplot(2, 4, 6)
plt.bar(genre_data['genre'], genre_data['sarcasm_rate'], color='orange', alpha=0.7)
plt.title('Sarcasm Rate by Genre')
plt.ylabel('Sarcasm Rate')
plt.xticks(rotation=45)

# 7. Sentiment Confidence Distribution
ax7 = plt.subplot(2, 4, 7)
plt.hist(df_sample['sentiment_confidence'], bins=50, alpha=0.7, color='purple')
plt.title('Sentiment Confidence Distribution')
plt.xlabel('Confidence Score')
plt.ylabel('Frequency')

# 8. Correlation Matrix
ax8 = plt.subplot(2, 4, 8)
correlation_cols = ['sentiment_compound', 'sentiment_confidence', 'is_sarcastic', 'year']
correlation_matrix = df_sample[correlation_cols].corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, square=True)
plt.title('Feature Correlation Matrix')

plt.tight_layout()
plt.savefig('imdb_sarcasm_sentiment_analysis.png', dpi=300, bbox_inches='tight')
plt.show()

# Advanced Interactive Visualizations with Plotly
print("Creating interactive visualizations...")

# Interactive Timeline with Dual Y-axis
fig_timeline = make_subplots(
    rows=2, cols=2,
    subplot_titles=('Sentiment Timeline', 'Sarcasm Rate Timeline',
                   'Genre Sentiment Distribution', 'Sentiment vs Sarcasm by Genre'),
    specs=[[{"secondary_y": True}, {"secondary_y": False}],
           [{"secondary_y": False}, {"secondary_y": False}]]
)

# Timeline plot
fig_timeline.add_trace(
    go.Scatter(x=timeline_data['year'], y=timeline_data['avg_sentiment'],
               mode='lines+markers', name='Average Sentiment', line=dict(width=3)),
    row=1, col=1
)

fig_timeline.add_trace(
    go.Scatter(x=timeline_data['year'], y=timeline_data['review_count'],
               mode='lines', name='Review Count', line=dict(dash='dash')),
    row=1, col=1, secondary_y=True
)

# Sarcasm rate timeline
fig_timeline.add_trace(
    go.Scatter(x=timeline_data['year'], y=timeline_data['sarcasm_rate'],
               mode='lines+markers', name='Sarcasm Rate', line=dict(color='red', width=3)),
    row=1, col=2
)

# Genre sentiment distribution
fig_timeline.add_trace(
    go.Bar(x=genre_data['genre'], y=genre_data['avg_sentiment'],
           name='Average Sentiment', marker_color='lightblue'),
    row=2, col=1
)

# Scatter plot: Sentiment vs Sarcasm by Genre
fig_timeline.add_trace(
    go.Scatter(x=genre_data['sarcasm_rate'], y=genre_data['avg_sentiment'],
               mode='markers+text', text=genre_data['genre'],
               textposition='top center', name='Genre Analysis',
               marker=dict(size=genre_data['review_count']/10,
                          color=genre_data['avg_sentiment'],
                          colorscale='RdYlBu')),
    row=2, col=2
)

fig_timeline.update_layout(height=800, showlegend=True,
                          title_text="IMDB Sarcasm-Aware Sentiment Analysis Dashboard")
fig_timeline.show()

# PERFORMANCE METRICS AND INSIGHTS
print("\n" + "="*50)
print("PERFORMANCE METRICS AND INSIGHTS")
print("="*50)

# Overall statistics
print(f"Total reviews analyzed: {len(df_sample)}")
print(f"Sarcastic reviews detected: {df_sample['is_sarcastic'].sum()} ({df_sample['is_sarcastic'].mean():.1%})")
print(f"Average sentiment score: {df_sample['sentiment_compound'].mean():.3f}")
print(f"Average confidence: {df_sample['sentiment_confidence'].mean():.3f}")

# Genre insights
print("\nGENRE INSIGHTS:")
for _, row in genre_data.iterrows():
    print(f"{row['genre'].capitalize()}: "
          f"Sentiment={row['avg_sentiment']:.3f}, "
          f"Sarcasm Rate={row['sarcasm_rate']:.1%}, "
          f"Reviews={row['review_count']}")

# Timeline insights
print("\nTIMELINE INSIGHTS:")
print(f"Most positive year: {timeline_data.loc[timeline_data['avg_sentiment'].idxmax(), 'year']}")
print(f"Most negative year: {timeline_data.loc[timeline_data['avg_sentiment'].idxmin(), 'year']}")
print(f"Highest sarcasm rate: {timeline_data.loc[timeline_data['sarcasm_rate'].idxmax(), 'year']}")

# Model validation
print("\nMODEL VALIDATION:")
# Compare sarcasm-aware vs traditional sentiment analysis
traditional_sentiment = df_sample['review'].apply(lambda x: SentimentIntensityAnalyzer().polarity_scores(x)['compound'])
sarcasm_aware_sentiment = df_sample['sentiment_compound']

# Calculate improvement in sentiment classification
improvement = abs(sarcasm_aware_sentiment - df_sample['sentiment'].apply(lambda x: 1 if x == 1 else -1)).mean()
baseline = abs(traditional_sentiment - df_sample['sentiment'].apply(lambda x: 1 if x == 1 else -1)).mean()

print(f"Traditional sentiment error: {baseline:.3f}")
print(f"Sarcasm-aware sentiment error: {improvement:.3f}")
print(f"Improvement: {((baseline - improvement) / baseline * 100):.1f}%")

# Save results
df_sample.to_csv('imdb_sarcasm_aware_results.csv', index=False)
timeline_data.to_csv('imdb_timeline_analysis.csv', index=False)
genre_data.to_csv('imdb_genre_analysis.csv', index=False)

print("\nAnalysis complete! Results saved to CSV files.")
print("Key innovations in this project:")
print("1. Sarcasm detection using pattern matching + sentiment contradiction + BERT")
print("2. Sentiment timeline analysis showing evolution over years")
print("3. Genre-aware sentiment filtering for contextual analysis")
print("4. Interactive visualizations for comprehensive insights")
print("5. Performance validation showing improvement over traditional methods")